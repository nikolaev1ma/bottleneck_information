\section{Проблема}

\subsection{Введение}
Представим, что нам требуется обучить нейронную сеть. Будем рассматривать обучение с учителем. Тогда у нас есть вход $X$ и выход $Y$, во время обучения нейронной сети алгоритм пытается найти оптимальные веса, чтобы по входу $x_i \in X$ сеть получала выход $y_i \in Y$.  Нейронная сеть представляет собой последовательность слоев $\{Z_0, Z_1, Z_2, ..., Z_n\}$ где $Z_0 = X, Z_n = Y^'$,где $Y^'$ предсказание сети, и набор функций преобразований $\{f_1, f_2, ..., f_n\}$ и веса $\{\theta_1, \theta_2, ..., \theta_n\}$ , где $Z_{i+1}= f_i(Z_i, \theta_i)$. Соответственно сеть преобразовывает исходное пространство $X$ в латентное представление $Z$, которое является сжатым представлением пространства $X$. Это значит что у хорошей модели латентное пространство включает в себя всю необходимую информацию о входе для представления предсказания о выходе. То есть нам необходимо перенести из входа минимальное количество информации для латентного пространства для максимально подробного описания выхода. Эта оптимизационная задача называется принципом бутылочного горлышка. Хочется решить эту оптимизационную задачу и изучить как перетекает информация между слоями взависимости от качества сети.

\subsection{Формальная постановка задачи}
\begin{enumerate}
    \item Изучить литературу про теорию информацию в нейронных сетях, взять за основу данные о поведении информарционных метрик в течение обучении сети и использовать их как гипотезу.
    \item Взятие за основу легкую нейроннуй сеть (сеть классификации цифр по фото), построить алгоритм ее обучения.
    \item Подробно изучить логическое устройство каждого из пространсв, на основе этих знаний построить статистическую оценку для кажого слоя.
    \item Построение на ней множества вероятностных пространств - для каждого слой свое множество пространств. Каждое вероятное пространство задается гиперпараметрами.
    \item Построить распределение для каждого слоя, и совместные распределения между слоями.
    \item Посчитать информацинные метрики (такие как энтропия) на полученных распределениях.
    \item Посмотреть на полученные информационные метрики в зависимости от эпохи обучения, сравнить с гипотезами, полученными с помощью литературы
    \item Провести валидацию, на этапе которой подобрать наилучшие гиперпараметры вероятностных пространств и соответственно понять преимущества и недостатки каждого из вероятностных пространств.
    \item Сделать выводы о проведенных экспериментов.
\end{enumerate}